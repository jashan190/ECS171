{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ff0359",
   "metadata": {},
   "source": [
    "Lab5: \n",
    "\n",
    "\n",
    "***Q1-In the context of Artificial Neural Networks, compare the application of “Softmax” with “Sigmoid” activation function in classification problems (binary and multi-class classification). Based on your research, which function is more appropriate for performing binary/multi-class classification? Why? Support your answer with a numerical example.*** \n",
    "Begin with https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af85278",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Sigmoid function is defined as:\n",
    "\n",
    "    sigma(x) = 1 / (1 + e^-x)\n",
    "\n",
    "It squashes any real-valued number into a range between 0 and 1. In the context of binary classification, sigmoid is ideal because it provides a probability-like output for a single class. When used for multi-label classification, sigmoid allows each output node to activate independently, which is useful when more than one class can be true.\n",
    "\n",
    "The Softmax function is defined as:\n",
    "\n",
    "    softmax(x_i) = e^(x_i) / sum(e^(x_j)) for all j\n",
    "\n",
    "This function also produces values between 0 and 1, but it additionally ensures that the outputs across all classes sum to 1. This makes it the preferred choice for multi-class classification where only one class is correct. Softmax interprets the output as a probability distribution across mutually exclusive classes.\n",
    "\n",
    "## When to Use Which Function\n",
    "\n",
    "- **Binary Classification**: Use Sigmoid. It outputs a single probability for the positive class and is suited to problems with two classes.\n",
    "- **Multi-Class Classification** (only one label correct): Use Softmax. It provides a distribution of probabilities across all classes, ensuring the total is 1.\n",
    "- **Multi-Label Classification** (multiple labels can be correct): Use Sigmoid. Each output is treated independently.\n",
    "\n",
    "## Numerical Example\n",
    "\n",
    "Suppose we have output logits: [2.0, 1.0, 0.1]\n",
    "\n",
    "**Sigmoid Outputs** (element-wise):\n",
    "- sigma(2.0) ≈ 0.88\n",
    "- sigma(1.0) ≈ 0.73\n",
    "- sigma(0.1) ≈ 0.52\n",
    "\n",
    "These outputs indicate each class could independently be active, appropriate for multi-label classification.\n",
    "\n",
    "**Softmax Output**:\n",
    "- softmax ≈ [0.65, 0.24, 0.11]\n",
    "\n",
    "These values represent a normalized probability distribution across all classes and are suitable for multi-class classification.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Sigmoid is best used for binary and multi-label classification tasks where classes are not mutually exclusive. Softmax is more appropriate for multi-class classification tasks where only one class is correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc27d89",
   "metadata": {},
   "source": [
    "***Q2- The following code is a Chat-GPT generated code.To run the provided code, install 'pgmpy' library by following the instructions in the provided linl. Look for installation through anaconda :  https://pgmpy.org/started/install.html***\n",
    "\n",
    "After completeing the installation process, study the tutorial for 'Bayesian Network' class provided in the 'pgmpy' library:  https://pgmpy.org/models/bayesiannetwork.html\n",
    "This documentation covers the syntax for creating a structure for a Bayesian Network model including adding features and dependencies between the features.\n",
    "\n",
    "Here is the source code for pgmpy.models.BayesianNetwork: \n",
    "https://pgmpy.org/_modules/pgmpy/models/BayesianNetwork.html#BayesianNetwork.add_edge\n",
    "\n",
    "\n",
    "Part 1) Using the following table and revise the probability values in the code below and include a conditional probability table based on the variables in this problem. Then Based on the structure of the model, provide the visualized Bayesian Network corresponding to the edges (i.e., dependencies) and the features (i.e., evidence).\n",
    "\n",
    "![Generated Dataset](lab5-cpt.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD\n",
    "student = DiscreteBayesianNetwork([('diff', 'grades'), ('aptitude', 'grades')])\n",
    "grades_cpd = TabularCPD('grades', 3, [[0.1,0.2,0.5,0.05,0.1,0.3],\n",
    "                                      [0.2,0.3,0.3,0.15,0.2,0.4],\n",
    "                                      [0.7,0.5,0.2,0.8,0.7,0.3]],\n",
    "                        evidence=['diff', 'aptitude'], evidence_card=[2, 3],\n",
    "                        state_names={'grades': ['gradeA', 'gradeB', 'gradeC'],\n",
    "                                     'diff': ['easy', 'hard'],\n",
    "                                     'aptitude': ['low', 'medium', 'high']})\n",
    "student.add_cpds(grades_cpd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c2fe1",
   "metadata": {},
   "source": [
    "Part 2) Based on the Bayes Theorem formula used in Bayesian Network classification, and given the conditional probability table above, for each class label, answer the following questions:\n",
    "- Provide the equation for computing P(grades|diff,aptitude) in terms of the hypothesis and evidence variables. \n",
    "- To compute P(grades='gradeA'|diff,aptitude), how many possible combinations of feature values for this class should be estimated? Explain your answer. \n",
    "- What is the predicted class label for P(grades|diff='easy',aptitude='high')? Support your answer with your computational work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e603ce0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since `grades` is conditionally dependent on `diff` and `aptitude`, we can use the CPT directly:\n",
    "\n",
    "**P(grades | diff, aptitude) = P(grades | diff, aptitude)**\n",
    "\n",
    "This is retrieved directly from the conditional probability table (CPT) defined in the network.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "- `diff` has 2 possible values: `easy`, `hard`\n",
    "- `aptitude` has 3 values: `low`, `medium`, `high`\n",
    "\n",
    "Total combinations = 2 × 3 = **6**\n",
    "\n",
    "For each of these combinations, we define a probability distribution over 3 possible values of `grades`: `gradeA`, `gradeB`, `gradeC`. Thus, 6 × 3 = 18 total entries are needed in the CPT, though only 12 are independent (since each row must sum to 1).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "From the CPT row corresponding to (aptitude = high, diff = easy):\n",
    "\n",
    "- gradeA: 0.5\n",
    "- gradeB: 0.3\n",
    "- gradeC: 0.2\n",
    "\n",
    "**Answer**:  \n",
    "P(grades = gradeA | diff = easy, aptitude = high) = **0.5**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Use `argmax`:\n",
    "\n",
    "- gradeA = 0.5\n",
    "- gradeB = 0.3\n",
    "- gradeC = 0.2\n",
    "\n",
    "**Predicted label: gradeA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e23f66",
   "metadata": {},
   "source": [
    "***Q3) Consider a scenario for diagnosing Flu infection.*** \n",
    "The variables are: \n",
    "    F: Has Flu (Yes/No)\n",
    "    C: Has Cough (Yes/No)\n",
    "    Fv: Has Fever (Yes/No)\n",
    "    T: Positive Flu Test (Yes/No)\n",
    "Assume the following dependecies:\n",
    "    Flu (F) influences both Cough (C) and Fever (Fv).\n",
    "    Flu (F) influences the result of the Flu Test (T).\n",
    "    \n",
    "Write the joint probability formula corresponding to this Bayesian Network and create a python implementation for such Bayesian Network to visualize the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0449b",
   "metadata": {},
   "source": [
    "**Variables**:\n",
    "- F: Has Flu (Yes/No)\n",
    "- C: Has Cough (Yes/No)\n",
    "- Fv: Has Fever (Yes/No)\n",
    "- T: Positive Flu Test (Yes/No)\n",
    "\n",
    "**Dependencies**:\n",
    "- F → C  \n",
    "- F → Fv  \n",
    "- F → T\n",
    "\n",
    "**Joint Probability**:\n",
    "\n",
    "P(F, C, Fv, T) = P(F) × P(C | F) × P(Fv | F) × P(T | F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f834103",
   "metadata": {},
   "source": [
    "***Q4) Application: Sentiment Prediction from Reviews***\n",
    "\n",
    "Variables in the Bayesian Network:\n",
    "    S: Sentiment of the Review (Positive / Negative)\n",
    "    P: Presence of Positive Words (e.g., \"amazing\", \"great\") (Yes/No)\n",
    "    N: Presence of Negative Words (e.g., \"terrible\", \"bad\") (Yes/No)\n",
    "    \n",
    "Dependencies:\n",
    "    The sentiment influences the likelihood of seeing positive or negative words.\n",
    "\n",
    "Suppose a review contains positive words and does not contain negative words. What is the probability that the sentiment is positive? Formulate your answer based on the above variables and dependecies. \n",
    "\n",
    "________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4316a96",
   "metadata": {},
   "source": [
    "**Variables**:\n",
    "- S: Sentiment of the Review (Positive/Negative)\n",
    "- P: Presence of Positive Words (Yes/No)\n",
    "- N: Presence of Negative Words (Yes/No)\n",
    "\n",
    "**Dependencies**:\n",
    "- S → P  \n",
    "- S → N\n",
    "\n",
    "**Structure**:\n",
    "- S → P  \n",
    "- S → N\n",
    "\n",
    "**Joint Probability**:\n",
    "\n",
    "P(S, P, N) = P(S) × P(P | S) × P(N | S)\n",
    "\n",
    "**Question**:  \n",
    "Suppose a review contains positive words and does NOT contain negative words (P=Yes, N=No). What is P(S=Positive | P=Yes, N=No)?\n",
    "\n",
    "Use Bayes’ Rule:\n",
    "\n",
    "P(S=Pos | P=Yes, N=No) ∝ P(S=Pos) × P(P=Yes | S=Pos) × P(N=No | S=Pos)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c817076",
   "metadata": {},
   "source": [
    "***Bayesian Information Criterion (BIC) is used to balance the fit of the model and model complexity.***\n",
    "\n",
    "BIC= −2⋅ln(L)+ k⋅ln(n)    // tends to prefer simpler models\n",
    "\n",
    "L= Maximum Likelihood of the model (how well the model fits the data)\n",
    "k: the number of parameters in the model\n",
    "n: the number of data points\n",
    "\n",
    "The first term rewards good fit (higher likelihood = better fit)\n",
    "The second term penalizes model complexity (more parameters = higher penalty)\n",
    "Lower BIC values are better. They represent a good tradeoff between simplicity and performance.\n",
    "\n",
    "Why use BIC in Bayesian Networks? \n",
    "    To decide between possible structures\n",
    "    To prevent overfitting by penalizing unnecessarily complex models.\n",
    "\n",
    "\n",
    "***Q5-Based on the information below, determine which model wins based on the BIC value? Given that Higher likelihood means the model fits the data better, provide a valid explanation. Support your answer with numeric computation.***\n",
    "\n",
    "    Model A: ln(L) = -150 , 4 parameters, 1000 samples\n",
    "\n",
    "    Model B: ln(L)=  -140, 8 parameters, 1000 samples\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64c908",
   "metadata": {},
   "source": [
    "The Bayesian Information Criterion (BIC) formula is:\n",
    "\n",
    "\\[\n",
    "\\text{BIC} = -2 \\cdot \\ln(L) + k \\cdot \\ln(n)\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( L \\): Maximum likelihood of the model (how well it fits the data)  \n",
    "- \\( k \\): Number of parameters  \n",
    "- \\( n \\): Number of samples  \n",
    "- Lower BIC is better (penalizes complexity)\n",
    "\n",
    "---\n",
    "\n",
    "### Given:\n",
    "\n",
    "- **Model A**: ln(L) = -150, k = 4, n = 1000  \n",
    "- **Model B**: ln(L) = -140, k = 8, n = 1000\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Compute BIC for each model\n",
    "\n",
    "**Model A**:\n",
    "\\[\n",
    "\\text{BIC}_A = -2 \\cdot (-150) + 4 \\cdot \\ln(1000)  \n",
    "= 300 + 4 \\cdot 6.9078 \\approx 300 + 27.63 = 327.63\n",
    "\\]\n",
    "\n",
    "**Model B**:\n",
    "\\[\n",
    "\\text{BIC}_B = -2 \\cdot (-140) + 8 \\cdot \\ln(1000)  \n",
    "= 280 + 8 \\cdot 6.9078 \\approx 280 + 55.26 = 335.26\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Compare\n",
    "\n",
    "- **Model A BIC** ≈ 327.63  \n",
    "- **Model B BIC** ≈ 335.26  \n",
    "\n",
    "**Model A wins** because it has a **lower BIC value**, meaning it achieves a better trade-off between model fit and simplicity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
