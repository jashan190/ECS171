{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637620a3",
   "metadata": {},
   "source": [
    "## Lab 4: The math behind Neural Networks\n",
    "\n",
    "#### In this lab, you will use the provided information below to answer 3 questions \n",
    "\n",
    "![Generated Dataset](./assets/lab4-1.jpg)\n",
    "![Generated Dataset](./assets/lab4-2.jpg)\n",
    "![Generated Dataset](./assets/lab4-3.jpg)\n",
    "![Generated Dataset](./assets/lab4-4.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacb6e6",
   "metadata": {},
   "source": [
    "Below we will ask for mathematical formulations: the above math for calculating loss is an example of what we mean by \"mathematical formulation\"\n",
    "\n",
    "- Question 1) Provide a mathematical formulation for calculating the forward-pass (computing the loss) for a minibatch of data with the above network. Let the size of your minibatch be m < n, where n is the size of the full dataset\n",
    "\n",
    "\n",
    "- Question 2) Provide the mathematical formulation for performing the backward-pass (backpropagation - computing and applying the gradients) for the same minibatch of data with the above network and calculating the weight updates at each layer of the network. \n",
    "\n",
    "\n",
    "- Question 3) Assume you have completed 1 epoch of training, provide the mathematical formulation for calculating the error of the model on both the training data and the testing data. Also, provide pseudocode to describe an algorithm for reporting the training and testing error after each epoch to investigate when the model converges.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5b32a",
   "metadata": {},
   "source": [
    "### Question 1 Answer:\n",
    "\n",
    "Mathematical formula for calculating the forward-pass: \n",
    "\n",
    "Input to first hidden layer:\n",
    "\\[\n",
    "z_{h1,j}^{(i)} = \\sum_{k=0}^{2} w_{ih_1,jk} x_k^{(i)}, \\quad a_{h1,j}^{(i)} = \\sigma(z_{h1,j}^{(i)})\n",
    "\\]\n",
    "\n",
    "First hidden layer to second hidden layer:\n",
    "\\[\n",
    "z_{h2,j}^{(i)} = \\sum_{k} w_{h1h2,jk} a_{h1,k}^{(i)} + b_{h2,j}, \\quad a_{h2,j}^{(i)} = \\sigma(z_{h2,j}^{(i)})\n",
    "\\]\n",
    "\n",
    "Second hidden layer to output layer:\n",
    "\\[\n",
    "z_{o,k}^{(i)} = \\sum_{j} w_{h2o,kj} a_{h2,j}^{(i)} + b_{o,k}, \\quad \\hat{y}_k^{(i)} = \\sigma(z_{o,k}^{(i)})\n",
    "\\]\n",
    "\n",
    "Mini-batch loss:\n",
    "\\[\n",
    "\\text{Loss} = \\frac{1}{2m} \\sum_{i=1}^{m} \\sum_{k=0}^{2} (y^{(i)} - \\hat{y}_k^{(i)})^2\n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec849f1",
   "metadata": {},
   "source": [
    "### Question 2 Answer:\n",
    "\n",
    "Mathematical formula for calcualting the backward-pass:\n",
    "\n",
    "Output layer error:\n",
    "\\[\n",
    "\\delta_{o,k}^{(i)} = (\\hat{y}_k^{(i)} - y^{(i)}) \\sigma'(z_{o,k}^{(i)})\n",
    "\\]\n",
    "\n",
    "Second hidden layer error:\n",
    "\\[\n",
    "\\delta_{h2,j}^{(i)} = \\left( \\sum_{k} \\delta_{o,k}^{(i)} w_{h2o,kj} \\right) \\sigma'(z_{h2,j}^{(i)})\n",
    "\\]\n",
    "\n",
    "First hidden layer error:\n",
    "\\[\n",
    "\\delta_{h1,j}^{(i)} = \\left( \\sum_{k} \\delta_{h2,k}^{(i)} w_{h1h2,kj} \\right) \\sigma'(z_{h1,j}^{(i)})\n",
    "\\]\n",
    "\n",
    "Gradients:\n",
    "\n",
    "For output layer weights:\n",
    "\\[\n",
    "\\Delta w_{h2o,kj} = \\frac{1}{m} \\sum_{i=1}^{m} \\delta_{o,k}^{(i)} a_{h2,j}^{(i)}\n",
    "\\]\n",
    "\n",
    "For second hidden layer weights:\n",
    "\\[\n",
    "\\Delta w_{h1h2,jk} = \\frac{1}{m} \\sum_{i=1}^{m} \\delta_{h2,j}^{(i)} a_{h1,k}^{(i)}\n",
    "\\]\n",
    "\n",
    "For input to first hidden layer weights:\n",
    "\\[\n",
    "\\Delta w_{ih_1,jk} = \\frac{1}{m} \\sum_{i=1}^{m} \\delta_{h1,j}^{(i)} x_k^{(i)}\n",
    "\\]\n",
    "\n",
    "Weight updates:\n",
    "\\[\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\Delta w\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76302c66",
   "metadata": {},
   "source": [
    "### Question 3 Answer:\n",
    "\n",
    "Mathematical Formulation for Error after 1 Epoch + Pseudocode:\n",
    "\n",
    "Training Error (after 1 epoch)\n",
    "\\[\n",
    "\\text{Training Error} = \\frac{1}{2n} \\sum_{i=1}^{n} \\sum_{k=0}^{2} (y^{(i)} - \\hat{y}_k^{(i)})^2\n",
    "\\]\n",
    "\n",
    "### Testing Error\n",
    "\\[\n",
    "\\text{Testing Error} = \\frac{1}{2n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} \\sum_{k=0}^{2} (y_{\\text{test}}^{(i)} - \\hat{y}_{k,\\text{test}}^{(i)})^2\n",
    "\\]\n",
    "\n",
    "### Pseudocode to Report Training and Testing Error after Each Epoch\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for mini_batch in training_data:\n",
    "        forward_pass(mini_batch)\n",
    "        backward_pass(mini_batch)\n",
    "        update_weights()\n",
    "\n",
    "    # After completing one epoch\n",
    "    training_error = compute_error(training_data)\n",
    "    testing_error = compute_error(testing_data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Training Error = {training_error}, Testing Error = {testing_error}\")\n",
    "\n",
    "    if convergence_criteria_met(training_error, testing_error):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
